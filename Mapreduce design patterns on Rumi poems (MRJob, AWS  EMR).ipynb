{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pattern 1: Filtering patterns\n",
    "Filtering: slicing the data based on a set of conditions.\n",
    "We are looking to find the top 10 longest sentences in Rumi poems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/rumi_top10.py\n"
     ]
    }
   ],
   "source": [
    "%%file codes/rumi_top10.py \n",
    "# this magic command allows saving output of python to folder\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRJobtoppoems(MRJob):\n",
    "    \n",
    "    \n",
    "    def mapper(self,_,line):\n",
    "        word_count = line.strip().split(' ')\n",
    "        yield None, (len(word_count), line)\n",
    "        \n",
    "    def reducer(self, _, len_line_pairs):\n",
    "        self.plist = []\n",
    "        self.llist = []\n",
    "        for v in len_line_pairs:\n",
    "            self.plist.append(v)\n",
    "        top10 = sorted(self.plist, reverse = True)[:10]\n",
    "        for m in top10:\n",
    "            yield m\n",
    "        \n",
    "    \n",
    "       \n",
    "if __name__ == '__main__':  \n",
    "    MRJobtoppoems.run()  # where MRJobCategoryCost is your job class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running this query took 7.614239931106567 seconds.\n",
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Running step 1 of 1...\n",
      "reading from STDIN\n",
      "15\t\"خموش این  بی  و این  تی  را به جادویی مده شکلی\"\n",
      "14\t\"نه از خاکم و نه از بادم نه از آتش و نه از آبم\"\n",
      "14\t\"از دل چه خوش دل می بری وز سر چه خوش سر می کشی\"\n",
      "13\t\"که آن سایه ست و این خورشید و آن پستست و این سامی\"\n",
      "13\t\"ره زن که خوش ره می زنی می کش که زیبا می کشی\"\n",
      "13\t\"بی دست و بی دل می شوم چون دست بر من می زنی\"\n",
      "13\t\"این کف به سر بر می رود چون سر به کیوان می کشی\"\n",
      "12\t\"یکی شاهی به معنی صد که جان و دل ز من بستد\"\n",
      "12\t\"گویم که  خمش کن که نه کی دانم و نی بی \"\n",
      "12\t\"که گوید شیر را هرگز   چه شیری تو که خونخواری \"\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "string =! python codes/rumi_top10.py < data/rumi.txt \n",
    "toc = time()\n",
    "\n",
    "print('Running this query took {} seconds.'.format(toc - tic))\n",
    "for s in string:\n",
    "    try:\n",
    "        print(codecs.decode(s, 'unicode_escape'))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pattern 2:  Summarization patterns:\n",
    "Let's find the mean number of characters in Rumi poem sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/sent_len.py\n"
     ]
    }
   ],
   "source": [
    "%%file codes/sent_len.py \n",
    "# this magic command allows saving output of python to folder\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRJobSentLen(MRJob):\n",
    "    \n",
    "    def mapper(self,_,line):\n",
    "        yield None, len(line)\n",
    "        \n",
    "    def reducer(self, _, lens):\n",
    "        n = total = 0\n",
    "        for l in lens:\n",
    "            n += 1\n",
    "            total += l\n",
    "            \n",
    "        yield \"Sentence length average:\", total / n\n",
    "        \n",
    "    \n",
    "       \n",
    "if __name__ == '__main__':  \n",
    "    MRJobSentLen.run()  # where MRJobCategoryCost is your job class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running this query took 2.440459728240967 seconds.\n",
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Running step 1 of 1...\n",
      "reading from STDIN\n",
      "\"Sentence length average:\"\t25.641\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "string =! python codes/sent_len.py < data/r.txt \n",
    "toc = time()\n",
    "\n",
    "print('Running this query took {} seconds.'.format(toc - tic))\n",
    "for s in string:\n",
    "    try:\n",
    "        print(codecs.decode(s, 'unicode_escape'))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pattern 3:  Structural patterns (join two tables):\n",
    "For this pattern, we need relational database structured kind of data (primary key, foreign key needs to be avaialble). Therefore, I am going to demonstrate this using other datasets.\n",
    "To do join using MRJob, we first need to concatanate the text files into one text file. This allows reading one stream of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/join.py\n"
     ]
    }
   ],
   "source": [
    "%%file codes/join.py \n",
    "#!/usr/bin/python\n",
    "\n",
    "# this magic command allows saving output of python to folder\n",
    "from mrjob.job import MRJob\n",
    "#from mr3px.csvprotocol import CsvProtocol # to output in csv format\n",
    "\n",
    "class MRJobJoin(MRJob):\n",
    "    #OUTPUT_PROTOCOL = CsvProtocol\n",
    "    def mapper(self,_,line):\n",
    "        data = line.split(\"\\t\")\n",
    "        if len(data) == 5 and data[0] != \"user_ptr_id\": # making sure we are skipping the header\n",
    "            user, reputation, gold, silver, bronze = data # unpacking the data\n",
    "            yield user, [\"U\", reputation, gold, silver, bronze]  # U is used to flag user database\n",
    "        elif len(data) == 19 and data[0] != \"id\": # making sure we are skipping the header\n",
    "            id_tag = data[0]\n",
    "            title = data[1]\n",
    "            tagnames = data[2]\n",
    "            user = data[3]\n",
    "            node_type = data[5]\n",
    "            parent_id = data[6]\n",
    "            abs_parent_id = data[7]\n",
    "            added_at = data[8]\n",
    "            score = data[9]\n",
    "            yield user, [\"N\", id_tag, title, tagnames, node_type, parent_id, abs_parent_id, added_at, score]\n",
    "            \n",
    "    def reducer(self, user, packed_values):\n",
    "        self.outlist = [None for _ in range(13)]  # empty list to keep the joined data\n",
    "        self.outlist[3] = user  # user id is the key\n",
    "        for line in packed_values:\n",
    "            if line[0] == 'U': # coming from the user file\n",
    "                self.outlist[9] = line[1] # reputation\n",
    "                self.outlist[10] = line[2] # gold\n",
    "                self.outlist[11] = line[3] # silver\n",
    "                self.outlist[12] = line[4] # bronze\n",
    "            elif line[0] == 'N':  # coming from the node file\n",
    "                self.outlist[0] = line[1]\n",
    "                self.outlist[1] = line[2]\n",
    "                self.outlist[2] = line[3]      \n",
    "                self.outlist[4] = line[4]\n",
    "                self.outlist[5] = line[5]\n",
    "                self.outlist[6] = line[6]\n",
    "                self.outlist[7] = line[7]      \n",
    "                self.outlist[8] = line[8]\n",
    "                yield None, self.outlist\n",
    "  \n",
    "       \n",
    "if __name__ == '__main__':  \n",
    "    MRJobJoin.run()  # where MRJobCategoryCost is your job class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running this query took 7.279247522354126 seconds.\n",
      "Using configs in C:\\Users\\Amin\\.mrjob.conf\n",
      "No configs specified for inline runner\n",
      "Running step 1 of 1...\n",
      "Creating temp directory C:\\Users\\Amin\\AppData\\Local\\Temp\\join.Amin.20190304.002055.195473\n",
      "job output is in C:\\Users\\Amin\\AppData\\Local\\Temp\\join.Amin.20190304.002055.195473\\output\n",
      "Streaming final output from C:\\Users\\Amin\\AppData\\Local\\Temp\\join.Amin.20190304.002055.195473\\output...\n",
      "Removing temp directory C:\\Users\\Amin\\AppData\\Local\\Temp\\join.Amin.20190304.002055.195473...\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "string =! python codes/join.py data/forum_users.tsv data/sample.tsv > outputs/users_node_joined.csv\n",
    "toc = time()\n",
    "\n",
    "print('Running this query took {} seconds.'.format(toc - tic))\n",
    "for s in string:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python codes/join.py -r emr s3://mapreduce0000/data/forum_users.tsv \\\n",
    "    s3://mapreduce0000/data/forum_node.tsv \\\n",
    "        --output-dir=s3://mapreduce0000/joined_tables/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
